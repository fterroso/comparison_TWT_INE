{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import os\n",
    "from geoalchemy2 import WKTElement\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_gdf = gpd.read_file(os.path.join('data', 'mov_areas_enriched.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_GRUPO</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>CPRO</th>\n",
       "      <th>NPRO</th>\n",
       "      <th>POB_GRUPO</th>\n",
       "      <th>LITERAL_GRUPO</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001A</td>\n",
       "      <td>8.237841e+07</td>\n",
       "      <td>3</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>7.903</td>\n",
       "      <td>Montesinos, Los y Algorfa</td>\n",
       "      <td>POLYGON ((696312.177 4215979.057, 696312.181 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001B</td>\n",
       "      <td>1.452931e+08</td>\n",
       "      <td>8</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>14.529</td>\n",
       "      <td>Sant Joan de Vilatorrada y otros municipios</td>\n",
       "      <td>POLYGON ((898992.611 4638407.292, 898992.603 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001M</td>\n",
       "      <td>4.756526e+08</td>\n",
       "      <td>28</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>5.149</td>\n",
       "      <td>Fuentidueña de Tajo y otros municipios</td>\n",
       "      <td>POLYGON ((494216.778 4445259.734, 494216.385 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001S</td>\n",
       "      <td>1.436231e+09</td>\n",
       "      <td>41</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>6.733</td>\n",
       "      <td>Real de la Jara, El y otros municipios</td>\n",
       "      <td>POLYGON ((240629.599 4209416.214, 240629.597 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001V</td>\n",
       "      <td>1.126422e+07</td>\n",
       "      <td>46</td>\n",
       "      <td>Valencia/Valéncia</td>\n",
       "      <td>6.277</td>\n",
       "      <td>Daimús y otros municipios</td>\n",
       "      <td>POLYGON ((748392.315 4317155.513, 748392.289 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_GRUPO    Shape_Area  CPRO               NPRO  POB_GRUPO  \\\n",
       "0     001A  8.237841e+07     3           Alicante      7.903   \n",
       "1     001B  1.452931e+08     8          Barcelona     14.529   \n",
       "2     001M  4.756526e+08    28             Madrid      5.149   \n",
       "3     001S  1.436231e+09    41            Sevilla      6.733   \n",
       "4     001V  1.126422e+07    46  Valencia/Valéncia      6.277   \n",
       "\n",
       "                                 LITERAL_GRUPO  \\\n",
       "0                    Montesinos, Los y Algorfa   \n",
       "1  Sant Joan de Vilatorrada y otros municipios   \n",
       "2       Fuentidueña de Tajo y otros municipios   \n",
       "3       Real de la Jara, El y otros municipios   \n",
       "4                    Daimús y otros municipios   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((696312.177 4215979.057, 696312.181 4...  \n",
       "1  POLYGON ((898992.611 4638407.292, 898992.603 4...  \n",
       "2  POLYGON ((494216.778 4445259.734, 494216.385 4...  \n",
       "3  POLYGON ((240629.599 4209416.214, 240629.597 4...  \n",
       "4  POLYGON ((748392.315 4317155.513, 748392.289 4...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 7)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   ID_GRUPO       3214 non-null   object  \n",
      " 1   Shape_Area     3214 non-null   float64 \n",
      " 2   CPRO           3214 non-null   int64   \n",
      " 3   NPRO           3214 non-null   object  \n",
      " 4   POB_GRUPO      3214 non-null   float64 \n",
      " 5   LITERAL_GRUPO  3214 non-null   object  \n",
      " 6   geometry       3214 non-null   geometry\n",
      "dtypes: float64(2), geometry(1), int64(1), object(3)\n",
      "memory usage: 175.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ma_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "e_date = datetime.datetime.strptime('2020-06-20', '%Y-%m-%d') #datetime.datetime.now()\n",
    "i_date = datetime.datetime.strptime('2020-03-20', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "delta = e_date - i_date       # as timedelta\n",
    "\n",
    "target_days = []\n",
    "for i in range(delta.days + 1):\n",
    "    day = i_date + timedelta(days=i)\n",
    "    target_days.append(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-based tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_point_tweets_with_target_areas_fn(gdf_t, target_areas_gdf):\n",
    "    grilled_gdf = gpd.sjoin(gdf_t, target_areas_gdf, how=\"inner\", op='intersects')\n",
    "    grilled_gdf.drop(columns='index_right lat lon text'.split(),inplace=True)\n",
    "    return grilled_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polygon based tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2239553275.937497"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mob_area_shape = ma_gdf['Shape_Area'].quantile(q=0.99)\n",
    "max_mob_area_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_centroid_tweets_with_target_areas_fn(gdf_t, target_areas_gdf):\n",
    "    grilled_gdf = gpd.sjoin(gdf_t, target_areas_gdf, how=\"inner\", op='intersects')\n",
    "    if 'text' in grilled_gdf.columns:\n",
    "        grilled_gdf.drop(columns='index_right text'.split(),inplace=True)\n",
    "    else:\n",
    "        grilled_gdf.drop(columns='index_right'.split(),inplace=True)\n",
    "    return grilled_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_polygon_tweet_file_fn(file_path):   \n",
    "    gdf_ = gpd.read_file(file_path, parse_dates=['timestamp'], driver='GeoJSON', encoding='utf-8').to_crs({'init': 'epsg:25830'})\n",
    "    gdf_['centroid']= gdf_['geometry'].apply(lambda x: x.centroid)\n",
    "    gdf_= gdf_.drop('geometry', 1)\n",
    "    gdf_= gdf_.rename(columns={'centroid':'geometry'})\n",
    "        \n",
    "    return gdf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_twt_stats():\n",
    "    global_n_tweets =0 \n",
    "    global_n_users= set()\n",
    "    for d in tqdm_notebook(target_days):\n",
    "        #point-based tweets\n",
    "        file_path = os.path.join(data_path, 'Spain-TWT-dataset_march_july_2020', 'point_tweets_{}.geojson'.format(d.strftime('%d-%m-%Y')))\n",
    "        point_gdf = None\n",
    "        if os.path.exists(file_path):\n",
    "            gdf = gpd.read_file(file_path, parse_dates=['timestamp'], driver='GeoJSON', encoding='utf-8').to_crs({'init': 'epsg:25830'})\n",
    "\n",
    "            global_n_tweets += gdf.shape[0]\n",
    "            global_n_users = global_n_users.union(set(gdf['user_id'].unique().tolist()))\n",
    "\n",
    "        #tweets with polygon geometry\n",
    "        file_path = os.path.join(data_path,  'Spain-TWT-dataset_march_july_2020', 'poly_tweets_{}.geojson'.format(d.strftime('%d-%m-%Y')))\n",
    "\n",
    "        poly_gdf= None\n",
    "        if os.path.exists(file_path):\n",
    "            gdf = gpd.read_file(file_path, parse_dates=['timestamp'], driver='GeoJSON', encoding='utf-8').to_crs({'init': 'epsg:25830'})\n",
    "\n",
    "            global_n_tweets += gdf.shape[0]\n",
    "            global_n_users = global_n_users.union(set(gdf['user_id'].unique().tolist()))\n",
    "\n",
    "    return global_n_tweets, global_n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aebeda30abd4a52b44065fc3168a759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=93), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_n_tweets, global_n_users= calculate_twt_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheer number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8210773"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_n_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheer number of unique tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_n_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the mapping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c031c5359434f0f98a5f862657eff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=93), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a3b0227d2a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpoly_gdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_polygon_tweet_file_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mglobal_n_tweets\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-f151a0776f19>\u001b[0m in \u001b[0;36mread_polygon_tweet_file_fn\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_polygon_tweet_file_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgdf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GeoJSON'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'epsg:25830'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'centroid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgdf_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgdf_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'centroid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.6/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             return GeoDataFrame.from_features(\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mf_filt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             )\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.6/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mfrom_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;31m# load geometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__geo_interface__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in tqdm_notebook(target_days):\n",
    "    #point-based tweets\n",
    "    file_path = os.path.join(data_path, 'Spain-TWT-dataset_march_july_2020', 'point_tweets_{}.geojson'.format(d.strftime('%d-%m-%Y')))\n",
    "    point_gdf = None\n",
    "    if os.path.exists(file_path):\n",
    "        gdf = gpd.read_file(file_path, parse_dates=['timestamp'], driver='GeoJSON', encoding='utf-8').to_crs({'init': 'epsg:25830'})\n",
    "        \n",
    "        global_n_tweets += gdf.shape[0]\n",
    "        global_n_users = global_n_users.union(set(gdf['user_id'].unique().tolist()))\n",
    "        \n",
    "        point_gdf = map_point_tweets_with_target_areas_fn(gdf, ma_gdf)\n",
    "        \n",
    "    #tweets with polygon geometry\n",
    "    file_path = os.path.join(data_path,  'Spain-TWT-dataset_march_july_2020', 'poly_tweets_{}.geojson'.format(d.strftime('%d-%m-%Y')))\n",
    "    \n",
    "    poly_gdf= None\n",
    "    if os.path.exists(file_path):\n",
    "        gdf = read_polygon_tweet_file_fn(file_path)\n",
    "        \n",
    "        global_n_tweets += gdf.shape[0]\n",
    "        global_n_users = global_n_users.union(set(gdf['user_id'].unique().tolist()))\n",
    "        \n",
    "        poly_gdf = map_centroid_tweets_with_target_areas_fn(gdf, ma_gdf)\n",
    "\n",
    "\n",
    "    #merge together the two dataframes\n",
    "    if (point_gdf is not None) and (poly_gdf is not None):\n",
    "        gdf_ = pd.concat([point_gdf, poly_gdf] , axis=0)\n",
    "        ordered_gdf = gdf_.sort_values(by='timestamp', ascending=True)\n",
    "        #ordered_gdf.to_file(os.path.join('data','tw_in_ma_{}.geojson'.format(d.strftime('%Y_%m_%d'))), driver=\"GeoJSON\")\n",
    "    elif point_gdf is not None:\n",
    "        point_gdf = point_gdf.sort_values(by='timestamp', ascending=True)\n",
    "        #point_gdf.to_file(os.path.join('data','tw_in_ma_{}.geojson'.format(d.strftime('%Y_%m_%d'))), driver=\"GeoJSON\")\n",
    "    elif poly_gdf is not None:\n",
    "        poly_gdf = poly_gdf.sort_values(by='timestamp', ascending=True)\n",
    "        #poly_gdf.to_file(os.path.join('data','tw_in_ma_{}.geojson'.format(d.strftime('%Y_%m_%d'))), driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"That's all folks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
